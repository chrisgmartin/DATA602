{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing the Music of The Beatles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "  * [Importing the Packages](#imports)\n",
    "  * [Getting the Song List and All Lyrics](#songgather)\n",
    "  * [Getting the Album Meta Data](#albummeta)\n",
    "  * [Getting the Singers List for Each Song](#singerslist)\n",
    "  * [Getting the List of All Songs on Each Album](#albumslist)\n",
    "  * [Merging and Cleaning the Tables](#merging)\n",
    "  * [Masking Word Clouds](#masking)\n",
    "  * [Songs Written by Each Artist WordCloud](#writtenby)\n",
    "  * [Songs Sung by Each Artist WordCloud](#sungby)\n",
    "  * [Answering Simple Questions](#questions)\n",
    "  * [For the Future](#future)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the Packages <a id=\"imports\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import string\n",
    "import codecs\n",
    "from django.utils.encoding import smart_str\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cStringIO\n",
    "from scipy.misc import imread\n",
    "from PIL import Image\n",
    "import PIL.ImageOps    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the Song List and All Lyrics <a id=\"songgather\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_songlist(urlname):\n",
    "    sock = urllib.urlopen(allsongsurl).read()\n",
    "    soup = BeautifulSoup(sock, 'html.parser')\n",
    "    table = soup.find(\"div\", {\"class\" : \"maincont floatfix\"})\n",
    "    #set parameters for dataframe\n",
    "    songnames = []\n",
    "    rows = table.findAll('td', {\"class\" : \"colfirst\"})\n",
    "    for row in rows:\n",
    "        songnames.append(row.find('a'))\n",
    "    songnames = pd.DataFrame(songnames[:200])\n",
    "    songnames = songnames.astype(str)\n",
    "    #extract URLs in Source column\n",
    "    songnames['source'] = songnames[0].str.extract('(\\\".*?\\\")', expand=True)\n",
    "    songnames['source'] = songnames['source'].str.replace('(\\\"\\/)', 'http://www.lyricsfreak.com/')\n",
    "    songnames['source'] = songnames['source'].str.replace('(\\\")', '')\n",
    "    #extract title in title column\n",
    "    songnames['Title'] = songnames[0].str.extract('(title\\=\\\".*?\\\")', expand=False)\n",
    "    songnames['Title'] = songnames['Title'].str.replace('(title\\=\\\")', '')\n",
    "    songnames['Title'] = songnames['Title'].str.replace('(Lyrics\\\")', '')\n",
    "    #drop initial column\n",
    "    return songnames.drop([0], axis=1)\n",
    "\n",
    "def get_lyrics(list):\n",
    "    lyric = []\n",
    "    lyrics = pd.DataFrame()\n",
    "    fulllyrics = []\n",
    "    lyrics['song'] = list['Title']\n",
    "    lyrics['source'] = list['source']\n",
    "    for song in list['source']:\n",
    "        sock = urllib.urlopen(song).read()\n",
    "        soup = BeautifulSoup(sock, 'html.parser')\n",
    "        table = soup.find(\"div\", {\"id\" : \"content_h\"})\n",
    "        lyric = smart_str(table)\n",
    "        lyric = string.replace(lyric, '<br>', ' ')\n",
    "        lyric = string.replace(lyric, '</br>', ' ')\n",
    "        lyric = string.replace(lyric, '<div class=\"dn\" id=\"content_h\">', ' ')\n",
    "        lyric = string.replace(lyric, '</div>', ' ')\n",
    "        fulllyrics.append(lyric)\n",
    "    lyrics['lyrics'] = fulllyrics\n",
    "    #remove extra whitespace from song names\n",
    "    lyrics['song'] = lyrics['song'].map(str.strip)\n",
    "    lyrics['song'] = lyrics['song'].str.lower()\n",
    "    lyrics['song'] = lyrics['song'].str.replace('[^a-zA-Z0-9\\n ]', '')\n",
    "    return lyrics\n",
    "\n",
    "def getothersongs(url):\n",
    "    sock = urllib.urlopen(url).read()\n",
    "    soup = BeautifulSoup(sock, 'html.parser')\n",
    "    table = soup.findAll('script')\n",
    "    pattern = r'(songs\\_non\\_display.*)'\n",
    "    songlist = re.search(pattern.decode('utf-8'), soup.decode('utf-8'), re.I | re.U)\n",
    "    songlist = songlist.groups()\n",
    "    songlist = smart_str(songlist)\n",
    "    songlist = str.split(songlist, 'colfirst')\n",
    "    lyric = []\n",
    "    lyrics = []\n",
    "    othersonglist = pd.DataFrame()\n",
    "    #gets newlist of htmls\n",
    "    for song in songlist:\n",
    "        lyric = str.replace(song, '\\\\', '')\n",
    "        pattern = r'(\\\"\\/.*?\\\")'\n",
    "        lyric = re.findall(pattern, lyric)\n",
    "        lyric = smart_str(lyric)\n",
    "        lyric = re.sub('\\\"', \"http://www.lyricsfreak.com\", lyric, count=1)\n",
    "        lyric = re.sub('\\\"', '', lyric)\n",
    "        lyric = re.sub('\\(', '', lyric)\n",
    "        lyric = re.sub('\\)', '', lyric)\n",
    "        lyric = re.sub('\\[', '', lyric)\n",
    "        lyric = re.sub('\\]', '', lyric)\n",
    "        lyric = re.sub('\\,', '', lyric)\n",
    "        lyric = re.sub('\\'', '', lyric)\n",
    "        lyrics.append(lyric)\n",
    "    #get list of song titles\n",
    "    songname = []\n",
    "    for song in songlist:\n",
    "        song1 = str.replace(song, '\\\\', '')\n",
    "        pattern = r'(title\\=\\\".*?\\\")'\n",
    "        song1 = re.findall(pattern, song1)\n",
    "        song1 = smart_str(song1)\n",
    "        song1 = re.sub('Lyrics', '', song1)\n",
    "        song1 = re.sub('title\\=\\\"', '', song1)\n",
    "        song1 = re.sub('\\[', '', song1)\n",
    "        song1 = re.sub('\\]', '', song1)\n",
    "        song1 = re.sub('\\(', '', song1)\n",
    "        song1 = re.sub('\\)', '', song1)\n",
    "        song1 = re.sub('\\\"', '', song1)\n",
    "        song1 = re.sub('\\'', '', song1)\n",
    "        song1 = re.sub('\\,', '', song1)\n",
    "        song1 = re.sub(\"\\\\\\\\\", \"'\", song1)\n",
    "        songname.append(song1)\n",
    "    othersonglist['song'] = songname\n",
    "    othersonglist['source'] = lyrics\n",
    "    #COMBINE LIST AND RETURN COMBINED LIST\n",
    "    return othersonglist[1:]\n",
    "\n",
    "def getotherlyrics(list):\n",
    "    lyric = []\n",
    "    lyrics = pd.DataFrame()\n",
    "    fulllyrics = []\n",
    "    lyrics['song'] = list['song']\n",
    "    lyrics['source'] = list['source']\n",
    "    for song in list['source']:\n",
    "        sock = urllib.urlopen(song).read()\n",
    "        soup = BeautifulSoup(sock, 'html.parser')\n",
    "        table = soup.find(\"div\", {\"id\" : \"content_h\"})\n",
    "        lyric = smart_str(table)\n",
    "        lyric = string.replace(lyric, '<br>', ' ')\n",
    "        lyric = string.replace(lyric, '</br>', ' ')\n",
    "        lyric = string.replace(lyric, '<div class=\"dn\" id=\"content_h\">', ' ')\n",
    "        lyric = string.replace(lyric, '</div>', ' ')\n",
    "        fulllyrics.append(lyric)\n",
    "    lyrics['lyrics'] = fulllyrics\n",
    "    lyrics['song'] = lyrics['song'].map(str.strip)\n",
    "    lyrics['song'] = lyrics['song'].str.lower()\n",
    "    lyrics['song'] = lyrics['song'].str.replace('[^a-zA-Z0-9\\n ]', '')\n",
    "    return lyrics\n",
    "\n",
    "allsongsurl = 'http://www.lyricsfreak.com/b/beatles/'\n",
    "songs = get_songlist(allsongsurl)\n",
    "alllyrics = get_lyrics(songs)\n",
    "othersongs = getothersongs(allsongsurl)\n",
    "otherlyrics = getotherlyrics(othersongs)\n",
    "\n",
    "alllyrics = alllyrics.append(otherlyrics, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the Album Meta Data <a id=\"albummeta\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_albums(urlname):\n",
    "    try:\n",
    "        sock = urllib.urlopen(urlname).read()\n",
    "    except:\n",
    "        print \"Error with %s, please retry using another url object\" % urlname\n",
    "    soup = BeautifulSoup(sock, 'html.parser')\n",
    "    soup.prettify()\n",
    "    table = soup.find(\"table\", {\"class\" : \"wikitable plainrowheaders\"})\n",
    "    #set parameters for dataframe\n",
    "    albumnames = []\n",
    "    A = []\n",
    "    B = []\n",
    "    C = []\n",
    "    D = []\n",
    "    E = []\n",
    "    F = []\n",
    "    G = []\n",
    "    H = []\n",
    "    I = []\n",
    "    #fill parameters for dataframe\n",
    "    for row in table.findAll('tr')[2:]:\n",
    "        albumnames.append(row.select('i'))\n",
    "        meta = row.findAll('td')\n",
    "        if len(meta) == 9:\n",
    "            A.append(meta[0].find(text=False))\n",
    "            B.append(meta[1].find(text=True))\n",
    "            C.append(meta[2].find(text=True))\n",
    "            D.append(meta[3].find(text=True))\n",
    "            E.append(meta[4].find(text=True))\n",
    "            F.append(meta[5].find(text=True))\n",
    "            G.append(meta[6].find(text=True))\n",
    "            H.append(meta[7].find(text=True))\n",
    "            I.append(meta[8].find(text=False))\n",
    "    #create dataframe\n",
    "    #convert list to dataframe\n",
    "    #remove last row, it references a footnote\n",
    "    albums = pd.DataFrame(albumnames[:28])\n",
    "    albums['Release'] = A\n",
    "    albums['UK Peak'] = B\n",
    "    albums['AUS Peak'] = C\n",
    "    albums['CAN Peak'] = D\n",
    "    albums['FRA Peak'] = E\n",
    "    albums['GER Peak'] = F\n",
    "    albums['NOR Peak'] = G\n",
    "    albums['US Peak'] = H\n",
    "    albums['Certifications'] = I\n",
    "    #fill missing albumn names due to multiple release dates with previous albumn name\n",
    "    albums[0] = albums[0].fillna(method='ffill')\n",
    "    #convert album names to string\n",
    "    albums[0] = albums[0].astype(str)\n",
    "    #create new column for album names without tags\n",
    "    albums['album'] = albums[0].str.extract('(\\\"\\>.*\\<\\/)', expand=False)    \n",
    "    #fill albums without tag\n",
    "    albums['album'] = albums['album'].fillna(albums[0])\n",
    "    #remove strange symbols from album names\n",
    "    albums['album'] = albums['album'].str.replace('(\\<\\/a\\>\\<\\/)', '')\n",
    "    albums['album'] = albums['album'].str.replace('(\\\"\\>)', '')\n",
    "    albums['album'] = albums['album'].str.replace('(\\<i\\>)', '')\n",
    "    albums['album'] = albums['album'].str.replace('(\\<\\/i\\>)', '')\n",
    "    #remove tags from Release Column\n",
    "    albums['Release'] = albums['Release'].astype(str)\n",
    "    albums['Release'] = albums['Release'].str.replace('(\\<.*?\\>)', '')\n",
    "    albums['Release'] = albums['Release'].str.replace('(\\\\n)', ' ')\n",
    "    #Remove tags from Certification Clumn\n",
    "    albums['Certifications'] = albums['Certifications'].astype(str)\n",
    "    albums['Certifications'] = albums['Certifications'].str.replace('(\\<.*?\\>)', '')\n",
    "    albums['Certifications'] = albums['Certifications'].str.replace('(\\[.*?\\])', ' |')\n",
    "    albums['Certifications'] = albums['Certifications'].str.replace('(\\\\n)', ' ')\n",
    "    #split certifications by |\n",
    "    albums['BPICert'] = albums['Certifications'].str.extract('(BPI.*?\\|)', expand=False)\n",
    "    albums['BPICert'] = albums['BPICert'].str.replace('(BPI\\:)', '')\n",
    "    albums['BPICert'] = albums['BPICert'].str.replace('(\\|)', '')\n",
    "    albums['ARIACert'] = albums['Certifications'].str.extract('(ARIA.*?\\|)', expand=False)\n",
    "    albums['ARIACert'] = albums['ARIACert'].str.replace('(ARIA\\:)', '')\n",
    "    albums['ARIACert'] = albums['ARIACert'].str.replace('(\\|)', '')\n",
    "    albums['MCCert'] = albums['Certifications'].str.extract('(MC.*?\\|)', expand=False)\n",
    "    albums['MCCert'] = albums['MCCert'].str.replace('(MC\\:)', '')\n",
    "    albums['MCCert'] = albums['MCCert'].str.replace('(\\|)', '')\n",
    "    albums['RIAACert'] = albums['Certifications'].str.extract('(RIAA.*?\\|)', expand=False)\n",
    "    albums['RIAACert'] = albums['RIAACert'].str.replace('(RIAA\\:)', '')\n",
    "    albums['RIAACert'] = albums['RIAACert'].str.replace('(\\|)', '')\n",
    "    albums['BVMICert'] = albums['Certifications'].str.extract('(BVMI.*?\\|)', expand=False)\n",
    "    albums['BVMICert'] = albums['BVMICert'].str.replace('(BVMI\\:)', '')\n",
    "    albums['BVMICert'] = albums['BVMICert'].str.replace('(\\|)', '')\n",
    "    albums['SNEPCert'] = albums['Certifications'].str.extract('(SNEP.*?\\|)', expand=False)\n",
    "    albums['SNEPCert'] = albums['SNEPCert'].str.replace('(SNEP\\:)', '')\n",
    "    albums['SNEPCert'] = albums['SNEPCert'].str.replace('(\\|)', '')\n",
    "    #rename some albums to match other dataframes\n",
    "    albums['album'] = albums['album'].str.replace('A Hard', 'Hard')\n",
    "    albums['album'] = albums['album'].str.replace('The Beatles', 'The Beatles (The White Album)')\n",
    "    albums['album'] = albums['album'].str.lower()\n",
    "    albums['album'] = albums['album'].str.replace('[^a-zA-Z0-9\\n ]', '')\n",
    "    #return albums dataframe\n",
    "    albums = albums.drop(albums.columns[[0, 1, 9]], axis=1)\n",
    "    return albums\n",
    "\n",
    "my_url3 = \"https://en.wikipedia.org/wiki/The_Beatles_discography#Albums\"\n",
    "albums = get_albums(my_url3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the Singers List for Each Song <a id=\"singerslist\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_singers(urlname):\n",
    "    try:\n",
    "        sock = urllib.urlopen(urlname).read()\n",
    "    except:\n",
    "        print \"Error with %s, please retry using another url object\" % urlname\n",
    "    soup = BeautifulSoup(sock, 'html.parser')\n",
    "    soup.prettify()\n",
    "    table = soup.find(\"table\", {\"class\" : \"wikitable collapsible sortable\"})\n",
    "    #set parameters for dataframe\n",
    "    songname = []\n",
    "    A = []\n",
    "    B = []\n",
    "    C = []\n",
    "    D = []\n",
    "    E = []\n",
    "    F = []\n",
    "    G = []\n",
    "    H = []\n",
    "    I = []\n",
    "    #fill parameters for dataframe\n",
    "    for row in table.findAll('tr')[1:]:\n",
    "        meta = row.findAll('td')\n",
    "        A.append(meta[0].find('a'))\n",
    "        B.append(meta[1].find(text=True))\n",
    "        C.append(meta[2].find(text=True))\n",
    "        D.append(meta[3].find(text=True))\n",
    "        E.append(meta[4].find(text=True))\n",
    "        F.append(meta[5].find(text=True))\n",
    "        G.append(meta[6].find(text=True))\n",
    "        H.append(meta[7].find(text=False))\n",
    "        #some songs have different info\n",
    "        I.append(meta[0].find(string=True))\n",
    "    #create dataframe\n",
    "    #convert list to dataframe\n",
    "    #remove last row, it references a footnote\n",
    "    singers = pd.DataFrame(songname)\n",
    "    singers[0] = A\n",
    "    singers['Year'] = B\n",
    "    singers['Songwriter'] = D\n",
    "    singers['LeadVocals'] = E\n",
    "    singers['UKChart'] = F\n",
    "    singers['USChart'] = G\n",
    "    singers['I'] = I\n",
    "    singers[0] = singers[0].astype(str)\n",
    "    #replace missing songs with \n",
    "    singers[0][singers[0] == 'None'] = singers['I']\n",
    "    #remove tag information from songs\n",
    "    singers['song'] = singers[0].str.replace('(\\<a.*?\\>)', '')\n",
    "    singers['song'] = singers['song'].str.replace('(\\<\\/a\\>)', '')\n",
    "    singers['song'] = singers['song'].str.replace('(\\\")', '')\n",
    "    singers['song'] = singers['song'].str.replace('[^a-zA-Z0-9\\n ]', '')\n",
    "    singers['song'] = singers['song'].str.lower()\n",
    "    singers = singers.drop(singers.columns[[0,1,4,5,6]], axis=1)\n",
    "    return singers\n",
    "\n",
    "singersurl = 'https://en.wikipedia.org/wiki/List_of_songs_recorded_by_the_Beatles'\n",
    "singerslist = get_singers(singersurl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the List of All Songs on Each Album <a id=\"albumslist\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_albumsonglist(urlname):\n",
    "    sock = urllib.urlopen(urlname).read()\n",
    "    soup = BeautifulSoup(sock, 'html.parser')\n",
    "    #extract list of album names and convert to series\n",
    "    albums1 = soup.findAll('h3')\n",
    "    albums1 = pd.Series(albums1[:])\n",
    "    #extract list of song names seperated by albums\n",
    "    songslist = soup.findAll('table')\n",
    "    songslist = songslist[2:]\n",
    "    albumlist = pd.DataFrame(songslist)\n",
    "    #merge albumns with songs\n",
    "    albumlist['albumnum'] = albumlist.index.tolist()\n",
    "    albumlist['album'] = albums1\n",
    "    albumlist['album'] = albumlist['album'].astype(str)\n",
    "    albumlist['album'] = albumlist['album'].str.replace('\\<.*?\\>', '')\n",
    "    albumlist['year'] = albumlist['album'].str.extract('(\\(\\d*?\\))', expand=False)\n",
    "    albumlist['year'] = albumlist['year'].str.replace('(\\()', \"\")\n",
    "    albumlist['year'] = albumlist['year'].str.replace('(\\))', \"\")\n",
    "    albumlist['album'] = albumlist['album'].str.replace('(\\(\\d*?\\))', '')\n",
    "\n",
    "    #get a list of the songs\n",
    "    A = []\n",
    "    B = []\n",
    "    num = 0\n",
    "    for row in albumlist[0]:\n",
    "        albumset = row\n",
    "        num = num\n",
    "        for link in albumset.findAll('a'):\n",
    "                A.append(link.string)\n",
    "                B.append(num)\n",
    "        num = num + 1\n",
    "    C = []\n",
    "    for song in A:\n",
    "        C.append(' '.join(song.split()))\n",
    "    songsalbums = pd.DataFrame(\n",
    "        {'song' : C,\n",
    "        'albumnum' : B,\n",
    "        })\n",
    "    albumlist = albumlist.drop(0, 1)\n",
    "    fullalbumslist = pd.merge(\n",
    "        songsalbums, albumlist,\n",
    "        left_on='albumnum', right_on='albumnum')\n",
    "    #remove extra whitespace from album names\n",
    "    fullalbumslist['album'] = fullalbumslist['album'].map(str.strip)\n",
    "    fullalbumslist['song'] = fullalbumslist['song'].str.replace('[^a-zA-Z0-9\\n ]', '')\n",
    "    fullalbumslist['song'] = fullalbumslist['song'].str.lower()\n",
    "    fullalbumslist['album'] = fullalbumslist['album'].str.replace('[^a-zA-Z0-9\\n ]', '')\n",
    "    fullalbumslist['album'] = fullalbumslist['album'].str.lower()\n",
    "    return fullalbumslist\n",
    "\n",
    "albumsongsurl = \"http://www.brianhartzog.com/beatles/beatles-list-of-all-lyrics-by-album.htm\"\n",
    "albumsongs = get_albumsonglist(albumsongsurl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging and Cleaning the Tables <a id=\"merging\"></a>\n",
    "\n",
    "Note:\n",
    "Yes, this process is incredibly hacky and there are easier ways to do it but I didn't do it those ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "completeset = pd.merge(\n",
    "    albumsongs, albums,\n",
    "    left_on='album', right_on='album')\n",
    "\n",
    "#some song names need to be cleaned before they can be merged\n",
    "alllyrics['song'] = alllyrics['song'] .str.replace('got to get it into my life', 'got to get you into my life')\n",
    "alllyrics['song'] = alllyrics['song'].str.replace('i want you', 'i want you shes so heavy')\n",
    "alllyrics['song'] = alllyrics['song'].str.replace('follow the sun', 'ill follow the sun')\n",
    "alllyrics['song'] = alllyrics['song'].str.replace('kansa city', 'medley kansas city  hey hey hey hey')\n",
    "alllyrics['song'] = alllyrics['song'].str.replace('^norwegian wood$', 'norwegian wood this bird has flown')\n",
    "alllyrics['song'] = alllyrics['song'].str.replace('revolution$', 'revolution 1')\n",
    "alllyrics['song'] = alllyrics['song'].str.replace('she is leaving home', 'shes leaving home')\n",
    "alllyrics['song'] = alllyrics['song'].str.replace('^money$', 'money thats what i want')\n",
    "alllyrics['song'] = alllyrics['song'].str.replace('sergeant', 'sgt')\n",
    "completeset['song'] = completeset['song'].str.replace(' reprise', '')\n",
    "alllyrics['song'] = alllyrics['song'].str.replace('you never give me your money thats what i want', 'you never give me your money')\n",
    "alllyrics['song'] = alllyrics['song'].str.replace('when im sixtyfour', 'when im sixty four')\n",
    "alllyrics['song'] = alllyrics['song'].str.replace('^i saw her standing$', 'i saw her standing there')\n",
    "alllyrics['song'] = alllyrics['song'].str.replace('dr robert', 'doctor robert')\n",
    "\n",
    "#clist = set(completeset['song'])\n",
    "#alist = set(alllyrics['song'])\n",
    "#clist - alist\n",
    "\n",
    "completeset = pd.merge(\n",
    "    completeset, alllyrics,\n",
    "    left_on='song', right_on='song')\n",
    "\n",
    "\n",
    "singerslist['song'] = singerslist['song'].str.replace('kansas city', 'medley kansas city  hey hey hey hey')\n",
    "singerslist['song'] = singerslist['song'].str.replace('please mr postman', 'please mister postman')\n",
    "singerslist['song'] = singerslist['song'].str.replace('when im sixtyfour', 'when im sixty four')\n",
    "singerslist['song'] = singerslist['song'].str.replace('youve really got a hold on me', 'you really got a hold on me')\n",
    "\n",
    "#clist = set(completeset['song'])\n",
    "#singlist = set(singerslist['song'])\n",
    "#clist - singlist\n",
    "\n",
    "completeset = pd.merge(\n",
    "    completeset, singerslist,\n",
    "    left_on='song', right_on='song')\n",
    "\n",
    "\n",
    "#FIX LeadVocals COLUMN\n",
    "#put in alphabetical order\n",
    "singlist = set(completeset['LeadVocals'])\n",
    "completeset['LeadVocals'] = completeset['LeadVocals'].str.replace(u'Harrison\\, with Lennon and McCartney', 'Harrison Lennon McCartney')\n",
    "completeset['LeadVocals'] = completeset['LeadVocals'].str.replace(u'Lennon and Harrison', 'Harrison Lennon')\n",
    "completeset['LeadVocals'] = completeset['LeadVocals'].str.replace(u'Lennon and McCartney', 'Lennon McCartney')\n",
    "completeset['LeadVocals'] = completeset['LeadVocals'].str.replace(u'Lennon\\, McCartney and Harrison', 'Harrison Lennon McCartney')\n",
    "completeset['LeadVocals'] = completeset['LeadVocals'].str.replace(u'Lennon\\, McCartney\\, Harrison', 'Harrison Lennon McCartney')\n",
    "completeset['LeadVocals'] = completeset['LeadVocals'].str.replace(u'Lennon\\, with McCartney', 'Lennon McCartney')\n",
    "completeset['LeadVocals'] = completeset['LeadVocals'].str.replace(u'Lennon\\, with Starkey', 'Lennon Starkey')\n",
    "completeset['LeadVocals'] = completeset['LeadVocals'].str.replace(u'McCartney\\, with Lennon\\, Harrison and Starkey', 'Harrison Lennon McCartney Starkey')\n",
    "completeset['LeadVocals'] = completeset['LeadVocals'].str.replace(u'McCartney\\, with Lennon', 'Lennon McCartney')\n",
    "completeset['LeadVocals'] = completeset['LeadVocals'].str.replace(u'Starkey \\(Best\\)', 'Starkey')\n",
    "\n",
    "#FIX Songwriter COLUMN\n",
    "#writelist = set(completeset['Songwriter'])\n",
    "completeset['Songwriter'] = completeset['Songwriter'].str.replace(u'Alexander', 'Other')\n",
    "completeset['Songwriter'] = completeset['Songwriter'].str.replace(u'Bacharach', 'Other')\n",
    "completeset['Songwriter'] = completeset['Songwriter'].str.replace(u'Berry', 'Other')\n",
    "completeset['Songwriter'] = completeset['Songwriter'].str.replace(u'Dixon', 'Other')\n",
    "completeset['Songwriter'] = completeset['Songwriter'].str.replace(u'Dobbins\\, Garrett\\, ', 'Other')\n",
    "completeset['Songwriter'] = completeset['Songwriter'].str.replace(u'Drapkin \\(aka Ricky Dee\\)', 'Other')\n",
    "completeset['Songwriter'] = completeset['Songwriter'].str.replace(u'Goffin', 'Other')\n",
    "completeset['Songwriter'] = completeset['Songwriter'].str.replace(u'Gordy', 'Other')\n",
    "completeset['Songwriter'] = completeset['Songwriter'].str.replace(u'Harrison\\, with uncredited contribution from Lennon', 'Harrison')\n",
    "completeset['Songwriter'] = completeset['Songwriter'].str.replace(u'Holly', 'Other')\n",
    "completeset['Songwriter'] = completeset['Songwriter'].str.replace(u'Johnson', 'Other')\n",
    "completeset['Songwriter'] = completeset['Songwriter'].str.replace(u'Leiber\\, Stoller', 'Other')\n",
    "completeset['Songwriter'] = completeset['Songwriter'].str.replace(u'Lennon and McCartney\\, with Starkey', 'Lennon McCartney Starkey')\n",
    "completeset['Songwriter'] = completeset['Songwriter'].str.replace(u'Lennon and McCartney', 'Lennon McCartney')\n",
    "completeset['Songwriter'] = completeset['Songwriter'].str.replace(u'Lennon with McCartney', 'Lennon McCartney')\n",
    "completeset['Songwriter'] = completeset['Songwriter'].str.replace(u'Lennon\\, with McCartney\\, Harrison and Starkey', 'Harrison Lennon McCartney Starkey')\n",
    "completeset['Songwriter'] = completeset['Songwriter'].str.replace(u'Lennon\\, with McCartney', 'Lennon McCartney')\n",
    "completeset['Songwriter'] = completeset['Songwriter'].str.replace(u'Lennon\\, with Ono and Harrison', 'Harrison Lennon Ono')\n",
    "completeset['Songwriter'] = completeset['Songwriter'].str.replace(u'McCartney\\, with Lennon', 'Lennon McCartney')\n",
    "completeset['Songwriter'] = completeset['Songwriter'].str.replace(u'Medley', 'Other')\n",
    "completeset['Songwriter'] = completeset['Songwriter'].str.replace(u'Perkins', 'Other')\n",
    "completeset['Songwriter'] = completeset['Songwriter'].str.replace(u'Robinson', 'Other')\n",
    "completeset['Songwriter'] = completeset['Songwriter'].str.replace(u'Russell', 'Other')\n",
    "completeset['Songwriter'] = completeset['Songwriter'].str.replace(u'Scott', 'Other')\n",
    "completeset['Songwriter'] = completeset['Songwriter'].str.replace(u'Starkey\\, with uncredited assistance from Harrison', 'Starkey')\n",
    "completeset['Songwriter'] = completeset['Songwriter'].str.replace(u'Traditional\\, arr\\. Lennon\\, McCartney\\, Harrison\\, Starkey', 'Harrison Lennon McCartney Starkey')\n",
    "completeset['Songwriter'] = completeset['Songwriter'].str.replace(u'Williams', 'Other')\n",
    "completeset['Songwriter'] = completeset['Songwriter'].str.replace(u'Willson', 'Other')\n",
    "completeset['Songwriter'] = completeset['Songwriter'].str.replace(u'Other\\, ', 'Other')\n",
    "\n",
    "#FIX lyrics COLUMN (remove symbols -- and replace ' with a space, lowercase)\n",
    "completeset['lyrics'] = completeset['lyrics'].str.replace('\\.\\.\\.', ' ')\n",
    "completeset['lyrics'] = completeset['lyrics'].str.replace('[^a-zA-Z0-9\\n ]', '')\n",
    "completeset['lyrics'] = completeset['lyrics'].str.lower()\n",
    "\n",
    "\n",
    "#change categorical rows for Songwriter and Singer to binary rows\n",
    "#writelist = set(completeset['Songwriter'])\n",
    "#Ono does not count, and is grouped with John\n",
    "completeset['HarrisonWrite'] = completeset['Songwriter'].str.find('Harrison')\n",
    "completeset['LennonWrite'] = completeset['Songwriter'].str.find('Lennon')\n",
    "completeset['McCartneyWrite'] = completeset['Songwriter'].str.find('McCartney')\n",
    "completeset['StarkeyWrite'] = completeset['Songwriter'].str.find('Starkey')\n",
    "completeset['OtherWrite'] = completeset['Songwriter'].str.find('Other')\n",
    "\n",
    "#singlist = set(completeset['LeadVocals'])\n",
    "completeset['HarrisonSing'] = completeset['LeadVocals'].str.find('Harrison')\n",
    "completeset['LennonSing'] = completeset['LeadVocals'].str.find('Lennon')\n",
    "completeset['McCartneySing'] = completeset['LeadVocals'].str.find('McCartney')\n",
    "completeset['StarkeySing'] = completeset['LeadVocals'].str.find('Starkey')\n",
    "completeset['OtherSing'] = completeset['LeadVocals'].str.find('N/A')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Masking Word Clouds  <a id=\"masking\"></a>\n",
    "### Songs Written by Each Artist  <a id=\"writtenby\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createwc(url, lyrics):\n",
    "    if url == georgepicurl:\n",
    "        stopwords = set(STOPWORDS)\n",
    "        image = cStringIO.StringIO(urllib.urlopen(url).read())\n",
    "        image_mask = Image.open(image).convert(\"L\")\n",
    "        image_mask = image_mask.point(lambda x: 0 if x<128 else 255)\n",
    "        image_mask = PIL.ImageOps.invert(image_mask)\n",
    "        image_mask = np.array(image_mask)\n",
    "        imagewc = WordCloud(background_color=\"white\", max_words=2000, mask=image_mask,\n",
    "                   stopwords=stopwords)\n",
    "        return image_mask, imagewc.generate(lyrics)\n",
    "    else:\n",
    "        stopwords = set(STOPWORDS)\n",
    "        image = cStringIO.StringIO(urllib.urlopen(url).read())\n",
    "        image_mask = Image.open(image).convert(\"L\")\n",
    "        image_mask = np.array(image_mask)\n",
    "        imagewc = WordCloud(background_color=\"white\", max_words=2000, mask=image_mask,\n",
    "                   stopwords=stopwords)\n",
    "        return image_mask, imagewc.generate(lyrics)        \n",
    "    \n",
    "georgepicurl = 'https://github.com/chrisgmartin/DATA605/raw/master/1_george.png'\n",
    "georgedf = completeset[completeset['HarrisonWrite'] != -1]\n",
    "georgedf = georgedf['lyrics']\n",
    "georgedf = str(list(georgedf))\n",
    "george_mask, georgewc = createwc(georgepicurl, georgedf)\n",
    "\n",
    "paulpicurl = 'https://github.com/chrisgmartin/DATA605/raw/master/2_paul.png'\n",
    "pauldf = completeset[completeset['McCartneyWrite'] != -1]\n",
    "pauldf = pauldf['lyrics']\n",
    "pauldf = str(list(pauldf))\n",
    "paul_mask, paulwc = createwc(paulpicurl, pauldf)\n",
    "\n",
    "ringopicurl = 'https://github.com/chrisgmartin/DATA605/raw/master/3_ringo.png'\n",
    "stardf = completeset[completeset['StarkeyWrite'] != -1]\n",
    "stardf = stardf['lyrics']\n",
    "stardf = str(list(stardf))\n",
    "star_mask, starwc = createwc(ringopicurl, stardf)\n",
    "\n",
    "johnpicurl = 'https://github.com/chrisgmartin/DATA605/raw/master/4_john.png'\n",
    "lennondf = completeset[completeset['LennonWrite'] != -1]\n",
    "lennondf = lennondf['lyrics']\n",
    "lennondf = str(list(lennondf))\n",
    "lennon_mask, lennonwc = createwc(johnpicurl, lennondf)\n",
    "\n",
    "fig = plt.figure()\n",
    "pic1 = fig.add_subplot(141)\n",
    "pic1.imshow(georgewc)\n",
    "pic1.axis(\"off\")\n",
    "plt.title('Harrison Wrote')\n",
    "pic2 = fig.add_subplot(142)\n",
    "pic2.imshow(paulwc)\n",
    "pic2.axis(\"off\")\n",
    "plt.title('McCartney Wrote')\n",
    "pic3 = fig.add_subplot(143)\n",
    "pic3.imshow(starwc)\n",
    "pic3.axis(\"off\")\n",
    "plt.title('Star Wrote')\n",
    "pic4 = fig.add_subplot(144)\n",
    "pic4.imshow(lennonwc)\n",
    "pic4.axis(\"off\")\n",
    "plt.title('Lennon Wrote')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Songs Sung by Each Artist  <a id=\"sungby\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "georgedf = completeset[completeset['HarrisonSing'] != -1]\n",
    "georgedf = georgedf['lyrics']\n",
    "georgedf = str(list(georgedf))\n",
    "george_mask, georgewc = createwc(georgepicurl, georgedf)\n",
    "\n",
    "pauldf = completeset[completeset['McCartneySing'] != -1]\n",
    "pauldf = pauldf['lyrics']\n",
    "pauldf = str(list(pauldf))\n",
    "paul_mask, paulwc = createwc(paulpicurl, pauldf)\n",
    "\n",
    "stardf = completeset[completeset['StarkeySing'] != -1]\n",
    "stardf = stardf['lyrics']\n",
    "stardf = str(list(stardf))\n",
    "star_mask, starwc = createwc(ringopicurl, stardf)\n",
    "\n",
    "lennondf = completeset[completeset['LennonSing'] != -1]\n",
    "lennondf = lennondf['lyrics']\n",
    "lennondf = str(list(lennondf))\n",
    "lennon_mask, lennonwc = createwc(johnpicurl, lennondf)\n",
    "\n",
    "fig = plt.figure()\n",
    "pic1 = fig.add_subplot(141)\n",
    "pic1.imshow(georgewc)\n",
    "pic1.axis(\"off\")\n",
    "plt.title('Harrison Sung')\n",
    "pic2 = fig.add_subplot(142)\n",
    "pic2.imshow(paulwc)\n",
    "pic2.axis(\"off\")\n",
    "plt.title('McCartney Sung')\n",
    "pic3 = fig.add_subplot(143)\n",
    "pic3.imshow(starwc)\n",
    "pic3.axis(\"off\")\n",
    "plt.title('Star Sung')\n",
    "pic4 = fig.add_subplot(144)\n",
    "pic4.imshow(lennonwc)\n",
    "pic4.axis(\"off\")\n",
    "plt.title('Lennon Sung')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answering Simple Questions  <a id=\"questions\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Let's try to answer a few questions:\n",
    "#Who wrote the most songs?\n",
    "pd.crosstab(index=completeset['Songwriter'], columns='count')\n",
    "#Who wrote the most songs?\n",
    "pd.crosstab(index=completeset['LeadVocals'], columns='count')\n",
    "\n",
    "#How many songs are on each US Chart-topping album (by chart ranking)?\n",
    "pd.crosstab(index=completeset['album'], columns=completeset['US Peak'])\n",
    "#How many songs are on each UK Chart-topping album (by chart ranking)?\n",
    "pd.crosstab(index=completeset['album'], columns=completeset['UK Peak'])\n",
    "#How many songs are on each BPI Certified album (by BPI Certification)?\n",
    "pd.crosstab(index=completeset['album'], columns=completeset['BPICert'])\n",
    "#How many songs are on each RIAA Certified album (by RIAA Certification)?\n",
    "pd.crosstab(index=completeset['album'], columns=completeset['RIAACert'])\n",
    "#How many songs were released by year (by album)?\n",
    "pd.crosstab(index=completeset['album'], columns=completeset['year'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For the Future  <a id=\"future\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, I found this to be a fun excersize in dealing with webscraping and figuring out how to merge various Pandas DataFrames when columns and rows do not match. There are several ways that this can be improved, absolutely. It is incredibly 'hacky' as it stands. Some suggestions:\n",
    "  * Use Parallel Processing to improve speed\n",
    "  * Better utilization of WordCloud (i.e. stopwords)\n",
    "  * Better formatting of 'Questions' section\n",
    "  * Detailed explainations of each step\n",
    "  * Improved WordCloud masking (i.e. font colours, image sizes, etc.)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
